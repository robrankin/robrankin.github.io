<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>azure - Tag - </title>
        <link>http://example.org/tags/azure/</link>
        <description>azure - Tag - </description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 21 Apr 2022 14:44:24 &#43;0100</lastBuildDate><atom:link href="http://example.org/tags/azure/" rel="self" type="application/rss+xml" /><item>
    <title>Packet Capture using tcpdump on Kubernetes Pods in Azure AKS</title>
    <link>http://example.org/posts/packet-capture-tcpdump-kubernetes-pods-azure/</link>
    <pubDate>Thu, 21 Apr 2022 14:44:24 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://example.org/posts/packet-capture-tcpdump-kubernetes-pods-azure/</guid>
    <description><![CDATA[Assuming the target containers can actually install new software (apt install is available) what follows is a quick and very dirty method to run tcpdump on k8s/AKS containers in Azure.
Install some needed utilities Use whatever pod label is required to target the right pods.
kubectl get pods -l &lt;LABEL&gt; -o name | \ xargs -I{} kubectl exec {} -- apt-get -y update kubectl get pods -l &lt;LABEL&gt; -o name | \ xargs -I{} kubectl exec {} -- \ apt-get -y install tcpdump screen psmisc rclone Check kubectl get pods -l &lt;LABEL&gt; -o name | \ xargs -I{} kubectl exec {} -- tcpdump --version Start tcpdump in a screen Use whatever tcpdump &lt;FILTER&gt; here as needed.]]></description>
</item><item>
    <title>Azure Translation Services with Elasticsearch and Logstash</title>
    <link>http://example.org/posts/azure-translation-services-elasticsearch-logstash/</link>
    <pubDate>Thu, 31 Mar 2022 06:54:40 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://example.org/posts/azure-translation-services-elasticsearch-logstash/</guid>
    <description><![CDATA[Recently had a need to parse some XML into Elasticsearch, specifically some CERT RSS feeds. Logstash has an RSS input, but it&rsquo;s a bit basic, and doesn&rsquo;t provide any language indications if the RSS feed includes them. One of the feeds I&rsquo;m using can be various languages per item, and many others are non-english entirely.
Since this would be parsing the same RSS feeds repeatedly, I need a predictable Document ID, so I can re-insert / upsert the item, and not create a new document every time the RSS feed is parsed.]]></description>
</item><item>
    <title>Shell script, Azure Storage using a Service Principle</title>
    <link>http://example.org/posts/shell-script-azure-storage-using-a-service-principle/</link>
    <pubDate>Tue, 20 Oct 2020 08:19:21 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://example.org/posts/shell-script-azure-storage-using-a-service-principle/</guid>
    <description><![CDATA[Needed something in shell to upload files to an Azure Storage account. Hopefully its useful for others, so put it up on Github here ( https://github.com/robrankin/bash-azure-storage )]]></description>
</item></channel>
</rss>
